% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/context_chat_client.R
\name{context_chat_client}
\alias{context_chat_client}
\title{context_chat_client}
\usage{
context_chat_client(
  model = "anthropic.claude-3-5-sonnet-20240620-v1:0",
  k = 10,
  system_prompt = "Answer concisely and use prior context.",
  ...
)
}
\arguments{
\item{model}{Bedrock model ID (default = Claude Sonnet 3.5).}

\item{k}{Maximum messages to retain in memory.}

\item{system_prompt}{System prompt for the LLM (used once when client is created).}

\item{...}{Additional args passed to \code{ellmer::chat_aws_bedrock()} (profile, api_args…).}
}
\value{
A \strong{list} with methods:  \cr
\itemize{
\item \verb{$chat(user_msg, followup = NULL)} – send a turn, get reply (character)  \cr
\item \verb{$memory()} – return the underlying \code{MemoryBuffer}  \cr
\item \verb{$clear()}  – clear the buffer  \cr
\item \verb{$get_turns()} – convenience \code{get_memory()} shortcut
}
}
\description{
Create a persistent chat client that automatically maintains
conversational memory with contextR and talks to Bedrock via \strong{ellmer}.
}
\examples{
\dontrun{
  cli <- context_chat_client(k = 6)
  cli$chat("Tell me about frogs in the USA.", followup = "Answer in 2 sentences.")
  cli$chat("What about Mexico?")
  cli$get_turns()
}
}
